{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7745098039215687\n",
      "Average Precision Score: 0.6588732744683498\n",
      "Kappa: 0.5390962671905697\n",
      "Hamming Loss: 0.22549019607843138\n",
      "AUC0.862460815047022\n",
      "Sensitivity0.7272727272727273\n",
      "Specificity0.8103448275862069\n",
      "Accuracy: 0.74\n",
      "Average Precision Score: 0.6288995215311004\n",
      "Kappa: 0.46457990115321257\n",
      "Hamming Loss: 0.26\n",
      "AUC: 0.7727272727272727\n",
      "Sensitivity0.6363636363636364\n",
      "Specificity0.8214285714285714\n",
      "0.7538330981670445\n"
     ]
    }
   ],
   "source": [
    "# %load features100.py\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,auc, precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import joblib\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from pyearth import Earth\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from skfeature.function.statistical_based import t_score\n",
    "from skfeature.function.statistical_based import gini_index\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from skfeature.function.similarity_based import reliefF\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from skfeature.function.information_theoretical_based import LCSI\n",
    "from skfeature.function.information_theoretical_based import MIM\n",
    "from skfeature.function.information_theoretical_based import MIFS\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "from skfeature.function.information_theoretical_based import CIFE\n",
    "from skfeature.function.information_theoretical_based import JMI\n",
    "from skfeature.function.information_theoretical_based import CMIM\n",
    "from skfeature.function.information_theoretical_based import ICAP\n",
    "from skfeature.function.information_theoretical_based import DISR\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "file_train = open(\"./csv/train.csv\")\n",
    "csv_f = csv.reader(file_train)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(\"./csv/train.csv\", names=features, usecols=range(1,6132), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "# INITIALIZING, CLEANING, AND STRATIFYING DATASET\n",
    "dataset[\"outcome\"] = pd.to_numeric(dataset[\"outcome\"], errors='coerce')\n",
    "dataset.dropna(axis=1, thresh=2, inplace=True)\n",
    "dataset.dropna(how='all',thresh = 20,inplace=True)\n",
    "train_feature = np.array(dataset)\n",
    "wh_inf = np.isinf(train_feature)\n",
    "train_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(train_feature)\n",
    "train_feature[wh_nan]=0\n",
    "\n",
    "file_validate = open(\"./csv/validation.csv\")\n",
    "csv_f = csv.reader(file_validate)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(\"./csv/validation.csv\", names=features, usecols=range(1,6132), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "# INITIALIZING, CLEANING, AND STRATIFYING DATASET\n",
    "dataset[\"outcome\"] = pd.to_numeric(dataset[\"outcome\"], errors='coerce')\n",
    "dataset.dropna(axis=1, thresh=2, inplace=True)\n",
    "validate_feature = np.array(dataset)\n",
    "wh_inf = np.isinf(validate_feature)\n",
    "validate_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(validate_feature)\n",
    "validate_feature[wh_nan]=0\n",
    "\n",
    "\n",
    "file_test = open(\"./csv/test.csv\")\n",
    "csv_f = csv.reader(file_test)\n",
    "features = next(csv_f)\n",
    "dataset = pd.read_csv(\"./csv/test.csv\", names=features, usecols=range(1,6132), dtype=np.float64, skiprows=1, low_memory=False)\n",
    "# INITIALIZING, CLEANING, AND STRATIFYING DATASET\n",
    "dataset[\"outcome\"] = pd.to_numeric(dataset[\"outcome\"], errors='coerce')\n",
    "dataset.dropna(axis=1, thresh=2, inplace=True)\n",
    "test_feature = np.array(dataset)\n",
    "wh_inf = np.isinf(test_feature)\n",
    "test_feature[wh_inf]=0\n",
    "wh_nan = np.isnan(test_feature)\n",
    "test_feature[wh_nan]=0\n",
    "\n",
    "\n",
    "#only use image features\n",
    "X_train = train_feature[:,:6130]\n",
    "Y_train = train_feature[:,6130]\n",
    "Y_train = Y_train.astype('int32')\n",
    "\n",
    "X_validate = validate_feature[:,:6130]\n",
    "Y_validate = validate_feature[:,6130]\n",
    "Y_validate = Y_validate.astype('int32')\n",
    "\n",
    "X_test = test_feature[:,:6130]\n",
    "Y_test = test_feature[:,6130]\n",
    "Y_test = Y_test.astype('int32')\n",
    "seed = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(X_train) \n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(Y_train)\n",
    "\n",
    "\n",
    "pipe = joblib.load('handpkl/NNetFSCR100.pkl')\n",
    "\n",
    "Y_pred = pipe.predict(X_validate)\n",
    "Y_prob = pipe.predict_proba(X_validate)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_validate, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_validate, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_validate, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_validate, Y_pred)))\n",
    "print(\"AUC\"+repr(roc_auc_score(Y_validate,Y_prob[:,1])))\n",
    "print(\"Sensitivity\" + repr(recall_score(Y_validate,Y_pred)))\n",
    "tn,fp,fn,tp = confusion_matrix(Y_validate,Y_pred).ravel()\n",
    "print(\"Specificity\" + repr(tn/(tn+fp)))\n",
    "\n",
    "        \n",
    "Y_pred = pipe.predict(X_test)\n",
    "Y_prob = pipe.predict_proba(X_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_prob[:,1])))\n",
    "print(\"Sensitivity\" + repr(recall_score(Y_test,Y_pred)))\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(\"Specificity\" + repr(tn/(tn+fp)))\n",
    "fpr, tpr, thresholds= precision_recall_curve(Y_test, Y_prob[:,1], pos_label=1)\n",
    "auc = auc(tpr,fpr)\n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.60-0.84)\n",
      "(0.43-0.81)\n",
      "(0.64-0.92)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#p is proportion of trials that were successes\n",
    "#n is the number of trials\n",
    "import math\n",
    "def adjusted_wald(p, n, z=1.96):\n",
    "    p_adj = (n * p + (z**2)/2)/(n+z**2)\n",
    "    n_adj = n + z**2\n",
    "    span = z * math.sqrt(p_adj*(1-p_adj)/n_adj)\n",
    "    return max(0, p_adj - span), min(p_adj + span, 1.0)\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.74), float(50))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.64), float(22))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.82), float(28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7941176470588235\n",
      "Average Precision Score: 0.6818775995246583\n",
      "Kappa: 0.5814771395076201\n",
      "Hamming Loss: 0.20588235294117646\n",
      "AUC0.8499216300940439\n",
      "Sensitivity0.7727272727272727\n",
      "Specificity0.8103448275862069\n",
      "Accuracy: 0.72\n",
      "Average Precision Score: 0.6054545454545455\n",
      "Kappa: 0.42622950819672123\n",
      "Hamming Loss: 0.28\n",
      "AUC: 0.7987012987012988\n",
      "Sensitivity0.6363636363636364\n",
      "Specificity0.7857142857142857\n",
      "0.7697348763359573\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 5 8 14\n"
     ]
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 50,22,28\n",
    "# 0.74,0.64,0.82\n",
    "# 0.72,0.64,0.79\n",
    "import sys\n",
    "from scipy.stats import binom_test\n",
    "#x accuracy\n",
    "#n = number of trials\n",
    "#p accuracy compare to\n",
    "x = 0.82\n",
    "n =28\n",
    "p = 0.79\n",
    "\n",
    "print(binom_test(int(x * n), n, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6130\n"
     ]
    }
   ],
   "source": [
    "#0.875,1.0,1.0\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = SelectKBest(fisher_score.fisher_score, k=100)\n",
    "best.fit(X_train, Y_train)\n",
    "idx = best.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "488\n",
      "665\n",
      "899\n",
      "1046\n",
      "1163\n",
      "1211\n",
      "1226\n",
      "1227\n",
      "1244\n",
      "1245\n",
      "1295\n",
      "1397\n",
      "1498\n",
      "1506\n",
      "1698\n",
      "1705\n",
      "1731\n",
      "1745\n",
      "1807\n",
      "1827\n",
      "1850\n",
      "1886\n",
      "1927\n",
      "1958\n",
      "2227\n",
      "2342\n",
      "2374\n",
      "2388\n",
      "2415\n",
      "2531\n",
      "2591\n",
      "2661\n",
      "2668\n",
      "2716\n",
      "2912\n",
      "3010\n",
      "3077\n",
      "117\n",
      "134\n",
      "158\n",
      "222\n",
      "238\n",
      "264\n",
      "281\n",
      "282\n",
      "288\n",
      "309\n",
      "310\n",
      "370\n",
      "371\n",
      "374\n",
      "441\n",
      "480\n",
      "510\n",
      "524\n",
      "541\n",
      "676\n",
      "777\n",
      "778\n",
      "858\n",
      "880\n",
      "968\n",
      "1048\n",
      "1056\n",
      "1160\n",
      "1330\n",
      "1354\n",
      "1417\n",
      "1418\n",
      "1526\n",
      "1530\n",
      "1560\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1945\n",
      "1951\n",
      "2042\n",
      "2080\n",
      "2084\n",
      "2098\n",
      "2119\n",
      "2131\n",
      "2151\n",
      "2157\n",
      "2187\n",
      "2196\n",
      "2204\n",
      "2284\n",
      "2425\n",
      "2668\n",
      "2693\n",
      "2698\n",
      "2766\n",
      "2802\n",
      "2891\n",
      "2956\n",
      "2963\n",
      "2999\n"
     ]
    }
   ],
   "source": [
    "for i in idx:\n",
    "    if i<3064:\n",
    "        i = i + 23\n",
    "    else:\n",
    "        i = i - 3064\n",
    "        if i>23:\n",
    "            i = i + 23\n",
    "            \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "179\n",
    "488\n",
    "665\n",
    "899\n",
    "1046\n",
    "1163\n",
    "1211\n",
    "1226\n",
    "1227\n",
    "1244\n",
    "1245\n",
    "1295\n",
    "1397\n",
    "1498\n",
    "1506\n",
    "1698\n",
    "1705\n",
    "1731\n",
    "1745\n",
    "1807\n",
    "1827\n",
    "1850\n",
    "1886\n",
    "1927\n",
    "1958\n",
    "2227\n",
    "2342\n",
    "2374\n",
    "2388\n",
    "2415\n",
    "2531\n",
    "2591\n",
    "2661\n",
    "2668\n",
    "2716\n",
    "2912\n",
    "3010\n",
    "3077\n",
    "3204\n",
    "3221\n",
    "3245\n",
    "3309\n",
    "3325\n",
    "3351\n",
    "3368\n",
    "3369\n",
    "3375\n",
    "3396\n",
    "3397\n",
    "3457\n",
    "3458\n",
    "3461\n",
    "3528\n",
    "3567\n",
    "3597\n",
    "3611\n",
    "3628\n",
    "3763\n",
    "3864\n",
    "3865\n",
    "3945\n",
    "3967\n",
    "4055\n",
    "4135\n",
    "4143\n",
    "4247\n",
    "4417\n",
    "4441\n",
    "4504\n",
    "4505\n",
    "4613\n",
    "4617\n",
    "4647\n",
    "4965\n",
    "4966\n",
    "4967\n",
    "5032\n",
    "5038\n",
    "5129\n",
    "5167\n",
    "5171\n",
    "5185\n",
    "5206\n",
    "5218\n",
    "5238\n",
    "5244\n",
    "5274\n",
    "5283\n",
    "5291\n",
    "5371\n",
    "5512\n",
    "5755\n",
    "5780\n",
    "5785\n",
    "5853\n",
    "5889\n",
    "5978\n",
    "6043\n",
    "6050\n",
    "6086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 1]\n",
      "[1, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 0]\n",
      "[0, 1, 1, 1, 1]\n",
      "[1, 0, 0, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 1, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[0, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 1]\n",
      "[0, 1, 1, 1, 1]\n",
      "[1, 1, 1, 0, 1]\n",
      "[1, 0, 1, 1, 1]\n",
      "[1, 0, 0, 0, 1]\n",
      "[0, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "file = open('./csv/experts_outcome.csv','r')\n",
    "expert = []\n",
    "for index,row in enumerate(csv.reader(file)):\n",
    "    if index == 0:\n",
    "        continue\n",
    "    tmp = [int(row[1]),int(row[2]),int(row[3]),int(row[4]),int(row[5])]\n",
    "    expert.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "Accuracy: 0.84\n",
      "Average Precision Score: 0.7568181818181817\n",
      "Kappa: 0.6721311475409836\n",
      "Hamming Loss: 0.16\n",
      "AUC: 0.7727272727272727\n",
      "Sensitivity0.7727272727272727\n",
      "25 3 5 17\n",
      "Specificity0.8928571428571429\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-393f65785c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Specificity\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mauc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file = open('./csv/experts_outcome.csv','r')\n",
    "expert = []\n",
    "for index,row in enumerate(csv.reader(file)):\n",
    "    if index == 0:\n",
    "        continue\n",
    "    tmp = [int(row[1]),int(row[2]),int(row[3]),int(row[4]),int(row[5])]\n",
    "    expert.append(tmp)\n",
    "expert = np.array(expert)\n",
    "Y_test = expert[:,4]\n",
    "Y_pred = expert[:,3]\n",
    "print(Y_test)\n",
    "print(\"Accuracy: \" + repr(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"Average Precision Score: \" + repr(average_precision_score(Y_test, Y_pred)))\n",
    "print(\"Kappa: \" + repr(cohen_kappa_score(Y_test, Y_pred)))\n",
    "print(\"Hamming Loss: \" + repr(hamming_loss(Y_test, Y_pred)))\n",
    "print(\"AUC: \" + repr(roc_auc_score(Y_test, Y_prob[:,1])))\n",
    "print(\"Sensitivity\" + repr(recall_score(Y_test,Y_pred)))\n",
    "tn,fp,fn,tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "print(\"Specificity\" + repr(tn/(tn+fp)))\n",
    "fpr, tpr, thresholds= precision_recall_curve(Y_test, Y_prob[:,1], pos_label=1)\n",
    "auc_ = auc(tpr,fpr)\n",
    "print(auc_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy:    0.76(0.62-0.86)  0.84(0.71-0.92)  0.84(0.71-0.92)  0.84(0.71-0.92)  avg: 0.82(0.69-0.90)\n",
    "Sensitivity: 0.73(0.52-0.87)  0.82(0.61-0.93)  0.73(0.52-0.87)  0.77(0.56-0.90)       0.76(0.55-0.89)\n",
    "Specificity: 0.79(0.61-0.90)  0.86(0.68-0.95)  0.93(0.76-0.99)  0.89(0.72-0.97)       0.87(0.69-0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69-0.90)\n",
      "(0.55-0.89)\n",
      "(0.69-0.96)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#p is proportion of trials that were successes\n",
    "#n is the number of trials\n",
    "import math\n",
    "def adjusted_wald(p, n, z=1.96):\n",
    "    p_adj = (n * p + (z**2)/2)/(n+z**2)\n",
    "    n_adj = n + z**2\n",
    "    span = z * math.sqrt(p_adj*(1-p_adj)/n_adj)\n",
    "    return max(0, p_adj - span), min(p_adj + span, 1.0)\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.82), float(50))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.76), float(22))))\n",
    "print(\"({:.2f}-{:.2f})\".format(*adjusted_wald(float(0.87), float(28))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2526064810983525\n"
     ]
    }
   ],
   "source": [
    "# 50,22,28\n",
    "# 0.74,0.64,0.82\n",
    "# 0.72,0.64,0.79\n",
    "import sys\n",
    "from scipy.stats import binom_test\n",
    "#x accuracy\n",
    "#n = number of trials\n",
    "#p accuracy compare to\n",
    "x = 0.82\n",
    "n =28\n",
    "p = 0.87\n",
    "\n",
    "print(binom_test(int(x * n), n, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand 0.14,0.21,0.25\n",
    "tpot 0.09,0.21,0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
